<!DOCTYPE html>
<html lang="en-US">
    <head>
        <title>Undergraduate Artificial Intelligence Group</title>
        <meta name="Keywords" content="university, of, toronto, artificial, intelligence, group">
			<meta name="Description" content="UAIG">
                <link rel="icon" href="icon.png" type="image/x-icon">
                    <link rel="stylesheet" type="text/css" href="style.css">
                        <link href="https://fonts.googleapis.com/css?family=Roboto:900" rel='stylesheet' type='text/css'>
                            <link href="https://fonts.googleapis.com/css?family=Open+Sans:300" rel='stylesheet' type='text/css'>
                        <script type="text/javascript" src="http://code.jquery.com/jquery-1.11.0.min.js"></script>
                        <script type="text/javascript" src="./uaig.js"></script>
    </head>
    <body>
        <div id="page">
        <div id="wrapper">
            <div id="main">
                <div id="c_splash_wrapper">
                    <div id="c_splash">
                        
                    </div>
                    <br>
                </div>
                <div id="c_join"><h2>Want to join?</h2><br>Send us an email. Come to our meetings. Whatever<br><br><img src="./guy.gif"></img></div>
                <div id="c_schedule"><h2>Winter 2014 Meetings</h2>
                    
                    <strong>Tuesday May 6, 2014 (2:00pm SF1105):</strong><br>
                    Panel Discussion: Transcendence and the upcoming AI singularity (<a href="media/transcendence-panel.mp4">video</a>)<br>
                    <br>
                    
                    <strong>Friday April 4, 2014 (4:30pm PT266):</strong><br>
                    UAIG Elections: help nurture a great AI community by unleashing your passion for AI!<br>
                    <br>
                    
                    <strong>Friday March 28, 2014 (4:30pm PT266):</strong><br>
                    UAIG AI&amp;Games 5: <b>"AI for real time game playing"</b> by Steve Engels (<a href="meetings/AIGames-Steve.pdf">slides</a>)<br>
                    <br>
                    
                    <strong>Friday March 21, 2014 (4:30pm PT266):</strong><br>
                    UAIG AI&amp;Games 3&amp;4: <b>"AI methods for Backgammon"</b> by Harun Mustafa<br>
                    followed by: <b>"Domain Independent Game playing"</b> by Daniel Kats (<a href="meetings/AIgames-Daniel.pdf">slides</a>)<br>
                    <br>
                    
                    <strong>Friday March 14, 2014 (4:30pm PT266):</strong><br>
                    Meeting cancelled: due to unforseen circumstances our speaker cannot make it this Friday, hence we will be combining both talks at the next meeting on Friday March 21! So come next week for an exciting double feature on domain
                    independent games and probabilistic game playing!<br>
                    <br>
                    
                    <strong>Friday March 7, 2014 (4:30pm PT266):</strong><br>
                    UAIG AI&amp;Games 2: <b>"Systems with General Intelligence: A New Perspective"</b> by Michael Thielscher<br>
                    <br>
                    
                    <strong>Friday February 28, 2014 (4:30pm PT266):</strong><br>
                    UAIG AI&amp;Games 1: Welcome to UAIG's new series of talks and events: AI&amp;Games! We are starting off with <b>"Turing Test for Game Bots"</b> by Avraham Sherman<br>
                    <br>
                    
                    <strong>Friday January 24, 2014 (4:30pm PT266):</strong><br>
                    UAIG grad talk 5 (<a href="meetings/uaig-2014winter2.ppt">slides</a>): [Computer Vision] <b>"Local models for shape and motion"</b> by Fernando Flores-Mangas<br>
                    <br>
                    
                    <strong>Friday February 7, 2014 (4:30pm PT266):</strong><br>
                    UAIG grad talk 4 (<a href="meetings/uaig-2014winter1.ppt">slides</a>): [Computational Linguistics] <b>"Interpreting Anaphoric Shell Nouns using Antecedents of Cataphoric Shell Nouns"</b> by Varada Kolhatkar<br>
                    <br>
                    
                    <h2>Fall 2013 Meetings</h2>
                    
                    <strong>Friday November 29, 2013 (4:30pm PT266):</strong><br>
                    UAIG grad talk 3 (<a href="meetings/uaig-2013fall6.ppt">slides</a>): [Computational Biology] <b>"Detecting Copy Number Variation in a Fetal Genome using Maternal Plasma Sequencing"</b> by Ladislav Rampášek<br>
                    <br>
                    
                    <strong>Wednesday November 27, 2013 (4:30pm PT378):</strong><br>
                    UAIG grad talk 2 (<a href="meetings/uaig-2013fall5.ppt">slides</a>): [Knowledge Representation] <b>"Elicitation and Approximately Stable Matching with Partial Preferences"</b> by Joanna Drummond<br>
                    <br>
                    
                    <strong>Friday November 22, 2013 (4:30pm PT266):</strong><br>
                    UAIG grad talk 1 (<a href="meetings/uaig-2013fall4.ppt">slides</a>): [Machine Learning] <b>"Convolutional Neural Nets for Computer Vision"</b> by Nitish Srivastava<br>
                    <br>
                    
                    <strong>Friday November 1, 2013 (4:30pm PT266):</strong><br>
                    Computational Economics (<a href="meetings/uaig-2013fall3.ppt">slides</a>): <b>"Multi-Dimensional Single-Peakedness and its Approximations"</b> by Alex Francois-Nienaber (<a href="meetings/MD-Spness-IJCAI.pptx">slides by Xin Sui</a>)<br>
                    <br>
                    
                    <strong>Friday October 18, 2013 (4:30pm PT266):</strong><br>
                    Reinforcement Learning (<a href="meetings/uaig-2013fall2.ppt">slides</a>)<br>
                    <br>
                    
                    <strong>Wednesday October 2, 2013 (4:30pm PT266):</strong><br>
                    Introductory meeting, AI Ethics (<a href="meetings/uaig-2013fall1.ppt">slides</a>)<br>
                    <br>
                    
                    <h2>Summer 2013 Meetings</h2>
                    
                    <strong>Friday May 10, 2013 (PT266):</strong><br>
                    UAIG met a few times over the summer (<a href="meetings/uaig-2013summer5.ppt">slides</a>)<br>
                    
                    <h2>Winter 2013 Meetings</h2>
                    
                    <strong>Wednesday April 3, 2013 (5pm BA5256):</strong><br>
                    Our final meeting of the semester will be this Wednesday April 3. The 
                    main purpose of the meeting will be to coordinate things for next year. 
                    If you're interested in getting involved in <span class="il">UAIG</span>,
                    or want to know more about that that would entail, please come out to 
                    this meeting. As usual, we'll be meeting in BA5256 at 5pm.<br>
                    <br>
                    
                    <strong>Wednesday March 27, 2013 (5pm BA5256):</strong><br>
                    Guest speaker: Frank Rudzicz<br>
                    Topic: Communicating with Machines: An Introduction to SPOClab<br>
                    Abstract: In this talk I introduce SPOClab (Signal Processing and Oral 
                    Communication), which bridges Computer Science at the University of 
                    Toronto with the Toronto Rehabilitation Institute. The goal of our lab 
                    is to produce software that helps to overcome challenges of 
                    communication including speech and language disorders. This will be 
                    organized into two co-dependent streams of research. First, we will 
                    embed control-theoretic models of speech production into augmented ASR 
                    systems using various machine-learning techniques. Second, these systems
                    will be deployed in software that can be used in practice; this 
                    involves adjacent disciplines such as human-computer interaction and 
                    general natural language processing to design and study application 
                    interfaces for disabled users.<br>
                    <br>
                    
                    <strong>Wednesday February 13, 2013 (5pm BA5256):</strong><br>
                    Guest speaker: Ilya Sutskever<br>
                    Topic: Image classification with convolutional neural networks<br>
                    Abstract: We describe an application of large convolutional neural 
                    networks to object recognition. Our network has 8 layers, 600 million 
                    connections, 60 million parameters, and 600,000 neurons, making it one 
                    of the largest neural networks ever trained. The network was trained to 
                    categorize images into 1000 lasses using the 1.2M training images of the
                    ImageNet Large Scale Visual Recognition Challenge 2012 competition. The
                    network was implemented on two GPUs and used a number of novel 
                    techniques to prevent overfitting. We entered a variant of this network 
                    to the ILSVRC-2012 competition and achieved a winning top-5 test error 
                    rate of 15.3%, compared to 26.2% achieved by the second-best entry. 
                    Additionally, the network's visual representation (which has 4096 
                    dimensions) outperformed 128 neurons from the IT area of a macaque's 
                    visual cortex at a certain recognition task that causes other computer 
                    vision systems to fail.<br>
                    This is joint work with Alex Krizhevksy and Geoffrey Hinton.<br>
                    Download the <a href="meetings/ImageNet.pdf">slides</a> from the talk.<br>
                    <br>
                    
                    <strong>Wednesday February 6, 2013 (5pm BA5256):</strong><br>
                    "Introductory" meeting (a little late).<br>
                    <br>
                    
                    <strong>Wednesday January 30, 2013 (5pm BA5256):</strong><br>
                    Guest speaker: Jackie Cheung<br>
                    Topic: Discovering Semantic Knowledge Using Distributional Information<br>
                    Abstract: Mapping a sentence or some other linguistic unit to a 
                    representation of its meaning is required for many complex tasks in 
                    natural language processing. In natural language semantics, there have 
                    been two major approaches to modelling meaning. One approach uses 
                    symbolic, logical representations and their associated logical inference
                    rules to represent and reason about the world. Another uses 
                    statistical, distributional information about the contexts in which a 
                    word or phrase appears in a large corpus of training text to model its 
                    meaning. I will show that distributional information can actually be 
                    used to discover the sort of semantic knowledge and structures used in 
                    the logical approach in two settings.<br>
                    <br>
                    
                    <strong>Wednesday January 23, 2013 (5pm BA5256):</strong><br>
                    Guest speaker: Abdel-rahman Mohamed<br>
                    Topic: How do machines recognize speech?<br>
                    Abstract: In this talk I will introduce the field of speech processing 
                    focusing on Automatic Speech Recognition (ASR). I will describe the 
                    basic blocks of a typical ASR system then I will describe our 
                    contributions at UofT to the state-of-the-art ASR system. The algorithms
                    we developed at UofT are the best performing ones at Google, IBM, and 
                    Microsoft research labs and are currently used in Google’s Android 4.1.<br>
                    <br>
                    
                    <h2>2012 Meetings</h2>
                    
                    <strong>Monday November 26, 2012 (5pm @ Top Sushi):</strong><br>
                    This will be our last official meeting of the semester. We'll take a 
                    break from the usual meeting format and meet at Top Sushi (just across 
                    the street on College) for dinner at the regular time, 5-6pm. We can 
                    discuss topics we covered this semester, themes (and projects!) for next
                    semester, and just plain socialize.<br>
                    <br>
                    
                    <strong>Monday November 19, 2012 (5pm BA5256):</strong><br>
                    This week we'll step back and take a broader look at the field of AI as a
                    whole. We'll discuss the variety of often divergent goals AI 
                    researchers have and the different motivations and assumptions 
                    underlying different approaches. Here is a diverse list of 
                    readings/videos related to these ideas. Investigate whatever you feel is
                    interesting, but feel free to show up at the meeting even if you 
                    haven't looked at any of them. This discussion should be pitched at such
                    a level that no specific prerequisite knowledge is required.<br>
                    
                    <strong>Recommended reading:</strong><br>
                    <ul>
                        <li>Bengio and LeCun's <em><a class="wiki_link_ext" href="http://yann.lecun.com/exdb/publis/pdf/bengio-lecun-07.pdf" rel="nofollow" target="_blank">Scaling Learning Algorithms Towards AI</a></em></li>
                        <li>Tom Griffith's <a class="wiki_link_ext" href="http://cocosci.berkeley.edu/tom/bayes.html" rel="nofollow" target="_blank">Bayesian reading list</a><br>
                            <li>Tenenbaum et al.'s <em><a class="wiki_link_ext" href="http://web.mit.edu/cocosci/Papers/tkgg-science11-reprint.pdf" rel="nofollow" target="_blank">How to Grow a Mind: Statistics, Structure, and Abstraction</a></em></li>
                            <li>MIT CogNet's article on <a class="wiki_link_ext" href="http://cognet.mit.edu.myaccess.library.utoronto.ca/library/erefs/mitecs/ai.intro.html#2" rel="nofollow" target="_blank">Computational Intelligence</a></li>
                            <li>The internet encyclopedia of philosophy's definition of <a class="wiki_link_ext" href="http://www.iep.utm.edu/art-inte/" rel="nofollow" target="_blank">Artificial Intelligence</a></li>
                    </ul>
                    
                    <strong>Recommended videos:</strong><br>
                    <ul>
                        <li>Henry Markham, director of the Blue Brain supercomputing project, gives a <a class="wiki_link_ext" href="http://www.ted.com/talks/henry_markram_supercomputing_the_brain_s_secrets.html" rel="nofollow" target="_blank">TED talk</a></li>
                        <li>Jeff Hawkins gives a <a class="wiki_link_ext" href="http://www.ted.com/talks/jeff_hawkins_on_how_brain_science_will_change_computing.html" rel="nofollow" target="_blank">TED talk</a> about how brain science will change computing</li>
                    </ul>
                    <br>
                    
                    <strong>Monday November 12, 2012:</strong><br>
                    No meeting - fall break!<br><br>
                    
                    <strong>Monday November 5, 2012 (5pm BA5256):</strong><br>
                    Guest speaker: Charlie Tang<br>
                    Topic: Deep Networks for Face Recognition<br>
                    Abstract: Visual perception is a challenging problem in part due to 
                    illumination variations. A possible solution is to first estimate an 
                    illumination invariant representation before using it for recognition. 
                    The object albedo and surface normals are examples of such 
                    representation. In this work, we introduce a multilayer generative model
                    where the latent variables include the albedo, surface normals, and the
                    light source. Combining Deep Belief Nets with the Lambertian 
                    reflectance assumption, our model can learn good priors over the albedo 
                    from 2D images. Illumination variations can be explained by changing 
                    only the lighting latent variable in our model. By transferring learned 
                    knowledge from similar objects, albedo and surface normals estimation 
                    from a <em>single</em> image is possible in our model. Experiments 
                    demonstrate that our model is able to generalize as well as improve over
                    standard baselines in <em>one-shot</em> face recognition.<br>
                    <br>
                    
                    <strong>Monday October 29, 2012 (5pm BA5256):</strong><br>
                    Sean will lead a discussion on deep belief nets<br>
                    <br>
                    <strong>Recommended reading:</strong><br>
                    <ul>
                        <li><em><a class="wiki_link_ext" href="http://www.cs.toronto.edu/%7Ehinton/absps/ncfast.pdf" rel="nofollow" target="_blank">A Fast Learning Algorithm for Deep Belief Nets</a></em>-
                            this introduces deep belief nets and the relevant concepts related to 
                            them. It's a pretty comprehensive overview and a good paper to start 
                            with.</li>
                        <li><em><a class="wiki_link_ext" href="http://www.cs.toronto.edu/%7Ehinton/absps/tics.pdf" rel="nofollow" target="_blank">Learning Multiple Layers of Representation</a></em>-
                            a less technical introduction to deep learning in general. Though many 
                            details are glossed over, it provides a good overview and is perhaps 
                            easier to read than the previous paper.</li>
                    </ul>
                    <strong>Optional reading:</strong> If you want to know more about contrastive divergence:<em><a class="wiki_link_ext" href="http://www.cs.toronto.edu/%7Ehinton/absps/cdmiguel.pdf" rel="nofollow" target="_blank">On Contrastive Divergence Learning</a></em><br>
                    <br>
                    
                    <strong>Monday October 22, 2012 (5pm BA5256):</strong><br>
                    Guest speaker: Paul Grouchy<br>
                    Topic: Evolutionary Algorithms and Artificial Intelligence<br>
                    Natural evolution has produced the most advanced intelligence discovered to 
                    date: our own. One would then expect that computer simulations of 
                    evolution could produce artificial intelligences. A variety of 
                    evolution-based programming techniques will be presented. Some of these 
                    techniques will be examples of Evolutionary Algorithms (EAs) as a form 
                    of AI, while others will showcase the power of EAs to artificially 
                    evolve neural network based AIs.<br>
                    Download the <a href="meetings/Evolutionary%20Algorithms%20and%20Artificial%20Intelligence.pptx">slides</a> from the talk.<br>
                    <br>
                    
                    <strong>Monday October 16, 2012 (5pm BA5256):</strong><br>
                    Intro to neural networks<br>
                    <strong>Recommended reading:</strong> <em><a class="wiki_link_ext" href="http://ai.stanford.edu/%7Ejoni/papers/LasersonXRDS2011.pdf" rel="nofollow">From Neural Networks to Deep Learning: Zeroing in on the Human Brain</a></em><br>
                    <strong>Recommended videos:</strong> <em><a class="wiki_link_ext" href="http://www.youtube.com/watch?v=AyzOUbkUf3M" rel="nofollow" target="_blank">The Next Generation of Neural Networks</a></em><br>
                    <br>
                    
                    <strong>Monday October 1, 2012 (5pm BA5256):</strong><br>
                    Introductory meeting<br>
                    <br>
                    
                    <h2>2011 Meetings</h2>
                    
                    <strong>November 28, 2011:</strong><br>
                    Professor Sheila McIlraith from the Knowledge &amp; Representation group will be presenting.<br>
                    <br>
                    
                    <strong>November 21, 2011:</strong><br>
                    No meeting. (award reception for NSERC recipients and others)<br>
                    <br>
                    
                    <strong>November 14, 2011:</strong><br>
                    Adam Golding on the computational modeling of preferences<br>
                    <br>
                    
                    <strong>October 31, 2011:</strong><br>
                    Meeting in PT266, 5-6 pm.<br>
                    Topic: Knowledge &amp; Representation<br>
                    Outline: We have two talks scheduled, see below:<br>
                    <br>
                    
                    <strong>5:00 – 5:30</strong><br>
                    Title: Plan Dispatchability: A Survey<br>
                    Author: Christian Muise<br>
                    In this talk we present the simple temporal network formalism, 
                    itsextensions, and the applications / solutions that have been presented
                    in the literature. A simple temporal network is a type of plan that describes
                    the events that must be executed, and the temporal constraints that must
                    be satisfied during execution. The focus will be primarily on showing the
                    consistency of temporal networks, and controllability of temporal networks
                    with uncertainty. We will also briefly cover some of the
                    more esoteric extensions to simple temporal networks that involve
                    resources, preferences, and choice of subplans.<br>
                    <br>
                    
                    <strong>5:30-6:00</strong><br>
                    Title: Solving QBF: CNF and alternatives<br>
                    Author: Alexandra Goultiaeva<br>
                    Quantified Boolean Formula (QBF) problem is a PSPACE-complete extension
                    of satisfiability (SAT) problem that allows the formulas to have
                    quantification. It can be used to naturally and efficiently represent
                    problems with adversarial dynamics, such as conditional planning,
                    as well as various problems in CAD and verification.
                    The most widespread approach to solving QBF is having a search-based
                    algorithm working on prenex Conjunctive Normal Form (CNF) representations.
                    However, in the recent years it has been shown that often relaxing these
                    constraints can be beneficial. This talk will outline the current approaches
                    to solving QBF formulas, as well as techniques for non-CNF and for
                    non-prenex reasoning.<br>
                    <br>
                    
                    <strong>October 17, 2011:</strong><br>
                    BACK IN ACTION – meetings on Mondays 5-6 pm in PT266<br>
                    <br>
                    With the following preliminary schedule:<br>
                    Oct. 24 – Misko Dzamba on computational biology<br>
                    Oct. 31 – KR Presentations<br>
                    Nov.7 – FALL BREAK (go read)<br>
                    Nov.14 – Chris Maddison on recurrent neural nets<br>
                    Nov.21 – Adam Golding on computational modeling of preferences<br>
                    <br>
                    
                    <strong>March 15, 2011:</strong><br>
                    Focus: knowledge and representation<br>
                    Guest speakers: Eric Hsu and Alexandra Goultiaeva<br>
                    topic: SAT solving<br>
                    <br>
                    
                    <strong>March 8, 2011:</strong><br>
                    Focus: computational linguistics<br>
                    Guest speaker: Chris Parisien<br>
                    Finding structure in the mire: Bayesian models of how children learn to use verbs<br>
                    Children are fantastic data miners. In the first few years of their 
                    lives, they discover a vast amount of knowledge about their native 
                    language. This means learning not just the abstract representations that
                    make up a language, but also learning how to generalize that knowledge 
                    to new situations — in other words, figuring out how language is 
                    productive. Given the noise and complexity in what kids hear, this is 
                    incredibly difficult, yet still, it seems effortless. In verb learning, a
                    lot of this generalization appears to be driven by strong regularities 
                    between form and meaning. Seeing how a certain verb has been used, kids 
                    can make a decent guess about what it means. Knowing what a verb means 
                    can suggest how to use it.<br>
                    In this talk, I present a series of hierarchical Bayesian models to 
                    explain how children can acquire and generalize abstract knowledge of 
                    verbs from the language they would naturally hear. Using a large, messy 
                    corpus of child-directed speech, these models can discover a broad range
                    of abstractions governing verb argument structure, verb classes, and 
                    alternation patterns. By simulating experimental studies in child 
                    development, I show that these complex probabilistic abstractions are 
                    robust enough to capture key generalization behaviours of children and 
                    adults. Finally, I will discuss some promising ways that the insights 
                    gained from modelling child language can benefit the development of a 
                    valuable large-scale linguistic resource, namely VerbNet.<br>
                    <br>
                    
                    <strong>March 1, 2011:</strong><br>
                    Focus: computational biology<br>
                    Guest speaker: Abe Heifets<br>
                    LigAlign: Flexible ligand-based active site alignment and analysis<br>
                    Ligand-based active site alignment is a widely adopted technique for the
                    structural analysis of protein–ligand complexes. However, existing 
                    tools for ligand alignment treat the ligands as rigid objects even 
                    though most biological ligands are flexible. We present LigAlign, an 
                    automated system for flexible ligand alignment and analysis. When 
                    performing rigid alignments, LigAlign produces results consistent with 
                    manually annotated structural motifs. In performing flexible alignments,
                    LigAlign automatically produces biochemically reasonable ligand 
                    fragmentations and subsequently identifies conserved structural motifs 
                    that are not detected by rigid alignment.<br>
                    (see readings for the full article)<br>
                    <br>
                    
                    <strong>February 22, 2011:</strong><br>
                    Reading week. No meeting.<br>
                    <br>
                    
                    <strong>February 15, 2011:</strong><br>
                    Focus: computational cognitive science<br>
                    In preparation for the Distinguished Lecture Series happening earlier 
                    the same day, members are asked to choose and read a paper by Josh 
                    Tenenbaum (see Readings section).<br>
                    The meeting will consist of a brief overview of the talk, as well as a discussion of the ideas and concepts related to Josh Tenenbaum’s research.<br>
                    <br>
                    
                    <strong>February 8, 2011:</strong><br>
                    Focus: cognitive science<br>
                    Adam Golding will lead the discussion.<br>
                    Everyone is asked to choose an article from one of the encyclopediae listed under readings.<br>
                    The group discussion will target the the heterogeneity/ecclectisim/pluralism inherent in cogsci.<br>
                    <br>
                    
                    <strong>February 1, 2011:</strong><br>
                    Focus: computer vision<br>
                    Title: The Need for Mid-Level Shape Priors in Object Categorization<br>
                    Invited speaker: Pablo Sala<br>
                    Object categorization plays an important role in computer vision and 
                    image retrieval. Although a trivial task for humans, this is an 
                    extremely challenging computational problem, which remains largely 
                    unsolved.<br>
                    Without knowing what they are looking at, humans have the ability to 
                    organize ambiguous visual stimuli into coherent groups. This important 
                    perception mechanism involved in the early stages of the object 
                    categorization process is called “perceptual grouping”.
                    Alghouth research in perceptual grouping was very active in the object 
                    recognition community until the mid-90s, in recent years most 
                    categorization researchers have moved to formulations of the recognition
                    problem as object detection.
                    However, recognition as detection does not scale to large object 
                    databases, where an informative shape index requires domain-independent 
                    (not object-specific) shape priors to drive the processes of perceptual 
                    grouping and perceptual abstraction.<br>
                    In this talk, I’ll present research on the problem of generic object 
                    recognition. Rather than assuming an object-level shape prior, I follow 
                    the classic formulation of the recognition problem and assume a 
                    vocabulary of compositional parts from which objects can be constructed.<br>
                    I’ll show an approach to group image contours into abstract 2-D parts 
                    and discuss various methods to select from among the set of generated 
                    2-D parts, a subset of parts that provides the best interpretation of 
                    the image. Finally, I’ll explain how the selected 2-D parts can be 
                    grouped into 3-D volumes abstracting the 3-D shapes in the scene.<br>
                    <br>
                    
                    <strong>January 25, 2011:</strong><br>
                    Focus: computational linguistics and NLP<br>
                    (same place and time as last week)<br>
                    Reading posted under the reading section and in dropbox.<br>
                    To continue our speech processing theme, we will also watch <a href="http://videolectures.net/mlcs07_monaghan_wip/">"words in puddles of sound"</a><br>
                    <br>
                    
                    <strong>January 18, 2011:</strong><br>
                    Focus: computational linguistics and NLP<br>
                    We are meeting 4-5 pm in BA5256 (this will be our regular room).<br>
                    Please read the paper posted under the ‘readings section’.<br>
                    Michelle will lead the discussion on authorship attribution, as well as 
                    provide us with an introduction to computational linguistics.<br>
                    <br>
                    
                    <strong>January 11, 2011:</strong><br>
                    Focus: computational linguistics – the problems<br>
                    <br>
                    
                    <h2>2010 Meetings</h2>
                    
                    <strong>December:</strong><br>
                    Break: do what you like.<br>
                    <br>
                    
                    <strong>November 29, 2010:</strong><br>
                    - focus: computer vision – features for detection, evolution of categorization<br>
                    <br>
                    
                    <strong>November 22, 2010:</strong><br>
                    - focus: human vision – research directions<br>
                    <br>
                    
                    <strong>November 15:</strong> we had presentations<br>
                    - focus: computer vision – methods<br>
                    - lead by Konstantine<br>
                    <br>
                    
                    <strong>November 8, 2010:</strong><br>
                    holiday<br>
                    <br>
                    
                    <strong>November 1, 2010:</strong><br>
                    - focus: intro to machine learning – methods<br>
                    - lead by Sean<br>
                    <br>
                    
                    <strong>October 21:</strong><br>
                    - introductory meeting<br>
                    - group discussion<br>
                    - administrative issues
                    <br>
                </div>
                <div id="c_members">wow nobody!</div>
                <div id="c_links">
                    <h2>Affiliations</h2>
                    
                    <a href="http://www.cogsci.ca/">CASA</a> - Cognitive Science and Artificial Intelligence Student Association<br>
                    
                    <a href="http://cssu.cdf.toronto.edu/">CSSU</a> - Computer Science Student Union<br>
                    
                    <a href="http://ucrg.sa.utoronto.ca/">UCRG</a> - Undergraduate Cognitive Robotics Group<br>
                    
                    <a href="http://ithreeuoft.blogspot.ca/">I3</a> - The Initiative for Inspiration and Innovation<br>
                    
                    <a href="http://brain.sa.utoronto.ca/">UTBC</a> - University of Toronto Brain Club<br>
                    
                    <a href="http://bpsu.blogs.chass.utoronto.ca/">BPSU</a> - Buddhism &amp; Psychology Student Union<br>
                    
                    <a href="http://chi.sa.utoronto.ca/">CHI</a> - Campus Health Initiative<br>
                    
                    <a href="http://jungiansociety.com/">UTJS</a> - University of Toronto Jungian Society<br>
                    
                    <a href="http://www.utgddc.com/">UTGDDC</a> - University of Toronto Game Design &amp; Development Club<br>
                    
                    <a href="http://naus.sa.utoronto.ca/">NAUS</a> - Neuroscience Association for Undergraduate Students<br>
                    
                    <a href="http://esa.sa.utoronto.ca/">ESA</a> - Economics Students' Association<br>
                    
                    <a href="http://www.utstat.toronto.edu/wordpress/?page_id=4080">UTSC</a> - University of Toronto Statistics Club<br>
                    
                    
                    <h2>Meeting and Mailing Lists</h2>
                    
                    <strong>AI Group (usually weekly meetings or seminars):</strong><br>
                    <ul>
                    <li>Machine Learning - e-mail <a class="wiki_link_ext" href="mailto:dtarlow@cs.toronto.edu" rel="nofollow">dtarlow@cs.toronto.edu</a> to get added</li>
                    <li>Computer Vision - check regularly: <a class="wiki_link_ext" href="http://www.cs.toronto.edu/vis/seminars/" rel="nofollow">http://www.cs.toronto.edu/vis/seminars/</a></li>
                    <li>Computational Linguistics - e-mail <a class="wiki_link_ext" href="mailto:gh@cs.toronto.edu" rel="nofollow">gh@cs.toronto.edu</a> to get added</li>
                    <li>Knowledge Representation - e-mail <a class="wiki_link_ext" href="mailto:alexia@cs.toronto.edu" rel="nofollow">alexia@cs.toronto.edu</a> to get added</li>
                    <li>Computational Biology - e-mail <a class="wiki_link_ext" href="mailto:brudno@cs.toronto.edu" rel="nofollow">brudno@cs.toronto.edu</a> to get added</li>
                    </ul>
                    
                    <h2>Miscellaneous links</h2>
                    
                    <ul>
                    <li><a class="wiki_link_ext" href="http://videolectures.net/Top/Computer_Science/" rel="nofollow" target="_blank">videolectures.net</a> - Like TED, except not for the masses ;)</li><li><a class="wiki_link_ext" href="http://ai-contest.com/" rel="nofollow" target="_blank">2011 AI Challenge</a> - update this link</li>
                    <li><a class="wiki_link_ext" href="http://www.aaai.org/Library/Magazine/magazine-library.php" rel="nofollow" target="_blank">AI Magazine</a> (requires University access)</li>
                    <li><a class="wiki_link_ext" href="https://www.coursera.org/category/cs-ai" rel="nofollow">AI courses</a> offered on Coursera</li>
                    <li><a class="wiki_link_ext" href="http://aitopics.org/" rel="nofollow">AI Topics</a></li>
                    </ul>
                </div>
                <div id="c_ai"><h2>The AI group</h2>
                    
                    One of the eleven research groups in the Department of Computer Science, the <a href="http://web.cs.toronto.edu/research/groups/ai.htm">AI group</a> is the University of Toronto's main outlet for research in Artificial Intelligence. The group is further divided into 5 groups: <a href="http://learning.cs.toronto.edu">ML</a>, <a href="http://www.cs.utoronto.ca/kr/">KR</a>, <a href="http://www.cs.utoronto.ca/compling/">CL</a>, <a href="http://www.cs.utoronto.ca/vis/">Vision</a>, <a href="http://compbio.cs.toronto.edu/cbl/">Bio</a>.
                    
                    <h2>Undergraduate Research Opportunities</h2>
                    
                    There are a few opportunities to conduct research with the AI group that are open to undergrad students. They are:<br>
                    <br>
                    
                    <strong>Funded Summer Research</strong>
                    <ul>
                        <li><strong>UTEA (NSE) - University of Toronto Excellence Awards (in the Natural Sciences & Engineering)</strong> - Presently the only research funding opportunity open to international students (with the URF); more info <a href="#utea">here</a>.</li>
                        <li><strong>(NSERC) USRA - (Natural Science and Engineering Research Council) Undergraduate Student Research Award</strong> - The standard option for Permanent residents or citizens of Canada; more info <a href="http://www.cs.toronto.edu/~pgries/usra/usra.html">here</a>.</li>
                        <li><strong>UTRECS - Undergraduate Toronto Research Experience in Computer Science</strong> - This is an opportunity for non-UofT undergraduate students to conduct research with the group; more info <a href="http://web.cs.toronto.edu/research/utrecs.htm">here</a>.</li>
                    </ul>
                    
                    <strong>Research Courses</strong>
                    <ul>
                        <li><strong>CSC490/CSC491</strong> - Students work on a research project in a class setting. More info <a href="http://www.artsandscience.utoronto.ca/ofr/calendar/crs_csc.htm#CSC490H1">here</a> (note that the link provided has been broken for years and that the best way to find out more info is by googling, visiting the undergraduate website or posting on the CDF forums).</li>
                        <li><strong>CSC494/CSC495</strong> - Students work individually with a professor, see info below on how to approach a professor.</li>
                    </ul>
                    
                    <strong>Other Research Opportunities</strong>
                    <ul>
                        <li><strong>URF - Undergraduate Research Fund</strong> - The Arts and Science Faculty's versatile research fund, note that it requires to justify all usage of the funding; more info <a href="http://www.artsci.utoronto.ca/current/scholarships/undergraduate-research-fund">here</a>.</li>
                        <li><strong>Research Assistant</strong> - A professor hires you outside the scope of the options above, you may receive a salary and/or office at the prof's discretion.</li>
                    </ul>
                    
                    <h2>How to get started on research?</h2>
                    
                    Read this <a href="http://web.cs.toronto.edu/program/ugrad/research.htm">page</a>.<br><br>
                    
                    <strong>Tips to approach a Professor:</strong><br>
                    <ul>
                        <li>Never start with: "Hello, are you busy?" -- professors are ALWAYS busy</li>
                        <li>Start by stating your name and how you know the prof. This is important because otherwise you force the prof into an awkward position where he/she uses background processes to figure out "who is this kid?"</li>
                        <li>When encountering a prof on campus, use clear formulations and specify the length of what you have to say; e.g. "Can you spare 3min today, I have this issue?", "Do you have 2min for a quick question?"</li>
                    </ul>
                    
                    <strong>Here is some good language for approaching a professor you've never formally met:</strong><br>
                    <br>
                    <p>"Hi, I'm -name-, we've seen each other around -area- / I took -course- with you. I'm interested in -research_area- and I'm wondering if you could give me some advice. I'm interested in pursuing a research project course or getting involved in some way. Do you know of any opportunities or might you be willing to supervise me yourself?"</p>
                    
                    <h2>What happens during research?</h2>
                    
                    Depending on the option chosen,...<br>
                    poster presentation / research report...<br>
                    add student testimonies?<br>
                    
                    <h2><a name="utea">UTEA information for Computer Science Students</a></h2>
                    
                    <strong>Application Deadline: </strong>Ask the <a href="http://web.cs.toronto.edu/program/ugrad.htm">Undergraduate Office</a> <br /><br />
                    
                    <strong>Application Instructions: <br /></strong>
                    1. <a href="research/UTEA-appl-part-1.doc">Part 1</a> should be completed by the student and possibly given to the proposed supervisor for review. <br />
                    2. The student is to provide a copy of his/her Complete Academic History (from ROSI). <br />
                    3. <a href="research/UTEA-appl-part-2.doc">Part 2</a> is to be completed by the supervisor and endorsed by the unit head or his/her designate. <br />
                    4. <a href="research/RIS-form.pdf">RIS</a> Application Attachment Form is to be filled out by the proposed supervisor. <br />
                    Both application forms with original signatures, the Complete Academic History, and a completed and signed RIS form should be delivered to the Department of Computer Science. <br /><br />
                    
                    <strong>Information from previous years: <br /></strong>
                    <a href="research/UTEA-2011.pdf">2011 UTEA information</a> <br />
                    <a href="research/UTEA-2012.pdf">2012 UTEA information</a> <br />
                    <a href="research/UTEA-2013.pdf">2013 UTEA information</a> <br />
                    <br /><br />
                    
                    <strong>Program Description: <br /></strong><br />
                    
                    <strong>Purpose: </strong>To provide opportunities for research experience at the undergraduate level in the natural sciences and engineering (NSE) or social sciences and humanities (SSH); to augment the formal research courses offered by the University of Toronto; to give undergraduate students opportunities to experience different approaches to research in various fields; to help students learn and appreciate the investigative methodology of areas of particular interest; and, to provide students with an experience that will allow them to make informed decisions about pursuing careers in research. <br /><br />
                    
                    <strong>Award Value: </strong>$4,500 provided by the University to be matched by a minimum of $1,125 by the student's supervisor and/ or department. Any supplement above this level may be set at the supervisor's or unit's discretion.<br /> <br />
                    
                    <strong>Duration:</strong> 16 full weeks in the summer term, between May 1 and September 30. <br />
                    
                    <h2>Undergraduate AI Courses</h2>
                    
                    Important: You have to petition to take engineering courses. Consult your Registrar.<br><br>
                    
                    <strong>KR</strong>
                    <ul>
                        <li>CSC200 Economic and Social Networks</li>
                        <li>CSC384 Artificial Intelligence</li>
                        <li>CSC486/2502 Knowledge Representation</li>
                        <li>MIE262 Operations Research I: Deterministic OR</li>
                        <li>MIE263 Operations Research II: Stochastic OR</li>
                        <li>MIE365 Operations Research III: Advanced OR</li>
                        <li>MIE367 Cases in Operational Research</li>
                        <li>MIE451 Decision Support Systems</li>
                    </ul>
                    <strong>ML</strong>
                    <ul>
                        <li>CSC310 Information Theory</li>
                        <li>CSC321 Neural Networks</li>
                        <li>CSC411 ML and Data Mining</li>
                        <li>CSC412/2506 Learning and Uncertainty</li>
                        <li>STA414 Statistical Methods for ML</li>
                        <li>ECE521 Inference Algorithms</li>
                    </ul>
                    <strong>CL</strong>
                    <ul>
                        <li>CSC401/2511 Natural Language Computing</li>
                        <li>CSC485/2501 Computational Linguistics</li>
                    </ul>
                    <strong>CV</strong>
                    <ul>
                        <li>CSC320 Visual Computing</li>
                        <li>CSC418/2504 Computer Graphics</li>
                        <li>CSC420 Image Understanding</li>
                        <li>ECE516 Intelligent Image Processing</li>
                    </ul>
                    
                    <h2>Graduate AI Courses</h2>
                    
                    Important: You have to petition to take graduate courses. Consult your Registrar.<br><br>
                    
                    <strong>KR</strong>
                    <ul>
                        <li>CSC2512 Advanced Propositional Reasoning</li>
                        <li>CSC2532 Dynamical Systems and Artificial Intelligence</li>
                        <li>CSC2533 Foundations of Knowledge Representation</li>
                        <li>CSC2534 Decision Making Under Uncertainty</li>
                        <li>CSC2542 Topics in Knowledge Representation and Reasoning</li>
                        <li>MIE562 Scheduling</li>
                        <li>MIE566 Decision Analysis</li>
                        <li>MIE468 Facility Planning</li>
                    </ul>
                    <strong>ML</strong>
                    <ul>
                        <li>CSC2416 Machine Learning Theory</li>
                        <li>CSC2515 Machine Learning</li>
                        <li>CSC2535 Advanced Machine Learning</li>
                        <li>CSC2541 Topics in Machine Learning</li>
                        <li>CSC2545 Kernel Methods and Support Vector Machines</li>
                        <li>STA4273 Statistical Machine Learning</li>
                        <li>ECE1775 Biologically Inspired Computing</li>
                        <li>PSL1071 Computational Neuroscience</li>
                    </ul>
                    <strong>CL</strong>
                    <ul>
                        <li>CSC2517 Discrete Mathematical Models of Sentence Structure</li>
                        <li>CSC2518 Spoken Language Processing</li>
                        <li>CSC2519 Natural Language Semantics</li>
                        <li>CSC2520 The Computational Lexicon</li>
                        <li>CSC2528 Advanced Computational Linguistics</li>
                        <li>CSC2540 Cognitive Linguistics</li>
                    </ul>
                    <strong>CV</strong>
                    <ul>
                        <li>CSC2503 Foundations of Computer Vision</li>
                        <li>CSC2523 Object Modeling and Recognition</li>
                        <li>CSC2529 Computer Animation</li>
                        <li>CSC2530 Computer Vision for Advanced Digital Photography</li>
                        <li>CSC2539 Topics in Computer Vision</li>
                        <li>ECE1772 Motion Analysis in Computer Vision</li>
                    </ul>
                    
                    <strong><br />Eligibility of Students for a UTEA: <br /></strong>
                    <br />Eligible: <br />- Canadian citizen, permanent resident of Canada, or foreign student with valid student visa for the full summer work term. <br />- At the time of application, registered as a full-time student in a bachelor's degree program at the University of Toronto. Graduating students who are only required to register part-time in their final session in order to complete degree requirements remain eligible. <br />- Must have obtained a cumulative average of "B+" or higher. For students in higher years, this average can be applied to the best two years of study. <br />- May already hold a bachelor's degree in any discipline and be studying towards a second bachelor's degree in the natural sciences and engineering (NSE). <br /><br />Ineligible: <br />- Currently enrolled in an undergraduate professional degree program in the health sciences (e.g., M.D., D.D.S., B.Sc.N.). Note that CIHR Undergraduate Health Professional Awards and the University of Toronto Life Sciences Committee's Undergraduate Research Opportunity Awards are available to students enrolled in these programs. <br />- Holds higher degrees in the natural sciences or engineering (NSE). <br /><br />To hold an award, students must: <br />- have been registered full-time in the term immediately before holding the award, unless only part-time study was required to complete degree requirements; <br />- not have started a program of graduate studies in the natural sciences or engineering (NSE); and <br />- be engaged on a full-time basis in research and development activities in the natural sciences or engineering (NSE) under the direction of an eligible supervisor during the award tenure. <br /><br />Please also note the following: <br />- A student may only be nominated in one department under one supervisor; and may not be nominated for both UTEA-SSH and UTEA-NSE in the same year. <br />- A student may not concurrently hold a UTEA and a NSERC Undergraduate Student Research Award (USRA). <br />- Preference will normally be given to second and third year students. <br />- A student may hold only one UTEA per fiscal year (i.e., April 1 to March 31). <br />- A student may hold a maximum of three UTEAs throughout his/her university career, although priority will be given to applicants who will be first-time holders if selected. <br />- Graduating students may hold an award in the term immediately following the completion of their undergraduate program requirements, as long as they have not started a program of graduate students. <br /><br />
                    
                    <strong>Supervision of UTEA Holders: <br /></strong>
                    Supervisor's Eligibility: <br />- There is a maximum of one UTEA-NSE applications per eligible supervisor. <br />- There is a maximum of three UTEA-NSE applications per unit. These must be ranked. <br />-  The supervisor of a UTEA holder must be a faculty member holding an eligible NSERC or SSHRC grant, either as the principal investigator or the co-investigator. <br />-  A supervisor must either hold an active NSERC research grant at the time his/her student holds the UTEA award (i.e. May 1 - September 30) or are actively seeking funding under the eligible NSERC programs as defined in this guideline document. In the latter case, an application must have been submitted to an eligible NSERC program by the supervisor at the time the student applies for a UTEA with the result of the NSERC application pending. <br /><br />Eligible SSHRC Programs: <br />- Holders of the following NSERC Research Grants are eligible to supervise students applying for UTEA-NSE: Discovery Grants (Individual, Group and Subatomic Physics Project and Northern Research Supplements); Collaborative Health Research Projects; Special Research Strategic Projects Grants; Strategic Networks Grants; Collaborative Research &amp; Development Grants; Idea to Innovation Program; NSERC/Canada Council for the Arts New Media Initiative; Research Partnership Agreements (RPA); Industrial Research Chairs; Chairs in Environmental Design and Engineering; Chairs in Design Engineering; Northern Research Chairs Program; Chairs for Women in Science and Engineering; University Faculty Awards; and Canada Research Chairs. <br />-  Researchers holding only NSERC Research Tools and Instruments and Infrastructure Grants are not eligible. <br /><br />Research Environment and Field Work: <br />- It is expected that provision will be made for alternative supervision of the student during absences of the supervisor, and that any additional costs related to field work (e.g. travel expenses) will be covered by the supervisor or the unit. <br /><br />
                    
                    <strong>Adjudication and Notification Process: <br /></strong>
                    Applications will be adjudicated on the following: <br />
                    - the excellence of the student's academic accomplishments <br />
                    - the strength of the project, including the quality of the research environment and supervision, and the nature of the student's participation. <br />
                    Potential to: <br />
                    - enhance the undergraduate experience in research <br />
                    - encourage research faculty to integrate undergraduate students in their research programs <br />
                    - support research growth in the unit <br />
                    - The adjudication committee will rank the applications received and a limited number of the highest-scoring applications will be offered UTEAs. <br />
                    -  Successful applicants will be notified around mid-April. Letters of award will follow once confirmation of acceptance of all awards has been received. <br />
                    -  In the event that a student turns down a UTEA award, the award will be offered to the next student on the adjudication committee's ranked list. <br /><br />

                </div>
                <div id="c_resources">
                        <h2>Videos</h2>
                        
                        ...<br>
                        
                        <h2>Lecture Notes</h2>
                        
                        ...<br>
                        
                        <h2>Readings</h2>
                        
                        
                        <strong>Monday November 19, 2012 (5pm BA5256):</strong><br>
                        <span style="font-size: 13.3333px;">Read and/or watch any of the following:</span><br>
                        - Bengio and LeCun, <em><a class="wiki_link_ext" href="http://yann.lecun.com/exdb/publis/pdf/bengio-lecun-07.pdf" rel="nofollow" target="_blank">Scaling Learning Algorithms Towards AI</a></em>,<br>
                        - <a class="wiki_link_ext" href="http://cocosci.berkeley.edu/tom/bayes.html" rel="nofollow" target="_blank">Tom Griffith's Bayesian reading list</a><br>
                        - Tenenbaum et al.'s <em><a class="wiki_link_ext" href="http://web.mit.edu/cocosci/Papers/tkgg-science11-reprint.pdf" rel="nofollow" target="_blank">How to Grow a Mind: Statistics, Structure, and Abstraction</a></em><br>
                        - <a class="wiki_link_ext" href="http://cognet.mit.edu.myaccess.library.utoronto.ca/library/erefs/mitecs/ai.intro.html#2" rel="nofollow" target="_blank">MIT CogNet: Computational Intelligence </a><br>
                        - "<a class="wiki_link_ext" href="http://www.iep.utm.edu/art-inte/" rel="nofollow" target="_blank">Artificial Intelligence</a>" definition by the internet encyclopedia of philosophy<br>
                        - <a class="wiki_link_ext" href="http://cognet.mit.edu.myaccess.library.utoronto.ca/library/erefs/mitecs/ai.intro.html#2" rel="nofollow" target="_blank">MIT CogNet: Computational Intelligence </a><br>
                        - Henry Markham, director of the Blue Brain supercomputing project, gives a <a class="wiki_link_ext" href="http://www.ted.com/talks/henry_markram_supercomputing_the_brain_s_secrets.html" rel="nofollow" target="_blank">TED talk</a><br>
                        - <a class="wiki_link_ext" href="http://www.ted.com/talks/jeff_hawkins_on_how_brain_science_will_change_computing.html" rel="nofollow" target="_blank">Jeff Hawkins TED talk</a> about how brain science will change computing<br>
                        <br>
                        <br>
                        <strong><span style="font-size: 13.3333px;">Monday October 29, 2012 :</span></strong><br>
                        <em><a class="wiki_link_ext" href="http://www.cs.toronto.edu/%7Ehinton/absps/ncfast.pdf" rel="nofollow" target="_blank">A Fast Learning Algorithm for Deep Belief Nets</a></em><br>
                        <em><a class="wiki_link_ext" href="http://www.cs.toronto.edu/%7Ehinton/absps/tics.pdf" rel="nofollow" target="_blank">Learning Multiple Layers of Representation</a></em><br>
                        <em><a class="wiki_link_ext" href="http://www.cs.toronto.edu/%7Ehinton/absps/cdmiguel.pdf" rel="nofollow" target="_blank">On Contrastive Divergence Learning</a></em><br>
                        <br>
                        <br>
                        <strong><span style="font-size: 13.3333px;">Monday October 16, 2012 :</span></strong><br>
                        <span style="font-size: 13.3333px;">Read and/or watch the following:</span><br>
                        <em><span style="font-size: 13.3333px;"> <a class="wiki_link_ext" href="http://ai.stanford.edu/%7Ejoni/papers/LasersonXRDS2011.pdf" rel="nofollow">From Neural Networks to Deep Learning: Zeroing in on the Human Brain</a></span></em><br>
                        <em><a class="wiki_link_ext" href="http://www.youtube.com/watch?v=AyzOUbkUf3M" rel="nofollow" target="_blank">The Next Generation of Neural Networks</a></em><br>
                        <br>
                        <br>
                        <strong><span style="font-size: 13.3333px;">November 14, 2011:</span></strong><br>
                        (from Adam Golding)<br>
                        For reading, people could read sections of interest from:<br>
                        <a class="wiki_link_ext" href="http://www.morganclaypool.com/doi/abs/10.2200/S00372ED1V01Y201107AIM014?journalCode=aim" rel="nofollow" target="_blank">http://www.morganclaypool.com/doi/abs/10.2200/S00372ED1V01Y201107AIM014?journalCode=aim</a><br>
                        With some emphasis on the more discrete/symbolic stuff in there. Or if 
                        they want to ‘go interdisciplinary’ they could choose among the readings
                        from this Seance:<br>
                        <a class="wiki_link_ext" href="http://www.facebook.com/event.php?eid=177720232316976" rel="nofollow" target="_blank">http://www.facebook.com/event.php?eid=177720232316976</a><br>
                        <br>
                        <strong>October 31, 2011:</strong><br>
                        Optional supplementary reading material:<br>
                        A Case for Simple SAT Solvers. Jinbo Huang. CP’07.<br>
                        <a class="wiki_link_ext" href="http://users.cecs.anu.edu.au/%7Ejinbo/07-cp.pdf" rel="nofollow" target="_blank">http://users.cecs.anu.edu.au/~jinbo/07-cp.pdf</a><br>
                        “It is a short paper, and gives an overview which I’d consider more modern<br>
                        (though some people might not agree). It also cites a lot of classic<br>
                        papers in the field.” (Alexandra G)<br>
                        <br>
                        <strong>March 1, 2011:</strong><br>
                        <a class="wiki_link_ext" href="http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6TGP-505NSC3-1&amp;_user=10&amp;_coverDate=08%2F24%2F2010&amp;_rdoc=1&amp;_fmt=high&amp;_orig=search&amp;_origin=search&amp;_sort=d&amp;_docanchor=&amp;view=c&amp;_acct=C000050221&amp;_version=1&amp;_urlVersion=0&amp;_userid=10&amp;md5=d732fbca050230d9597c9830c6c4829d&amp;searchtype=a" rel="nofollow">LigAlign: Flexible ligand-based active site alignment and analysis </a>by Abraham Heifets and Ryan H.Lilien<br>
                        <br>
                        <strong>February 22, 2011:</strong> Reading week, ironically :)<br>
                        <br>
                        <strong>February 15, 2011:</strong><br>
                        Choose a paper from the special issue in <a class="wiki_link_ext" href="http://www.sciencedirect.com/science?_ob=PublicationURL&amp;_tockey=%23TOC%236061%232006%23999899992%23628801%23FLA%23&amp;_cdi=6061&amp;_pubType=J&amp;view=c&amp;_auth=y&amp;_acct=C000050221&amp;_version=1&amp;_urlVersion=0&amp;_userid=10&amp;md5=5a1202a66a6c3bb59dcc401cfb44ed68" rel="nofollow">Trends in Cognitive Sciences</a>,<br>
                        particularly something written by Joshua B. Tenenbaum<br>
                        If you’re feeling lazy and just want to be given a paper to read, then at least read this:<br>
                        <a class="wiki_link_ext" href="http://web.mit.edu/cocosci/Papers/ChaterTenenbaumYuille-TICS06.pdf" rel="nofollow">Probabilistic models of cognition: Conceptual foundations</a>. Chater, N., Tenenbaum, J. B., and Yuille, A.<br>
                        If you’re feeling more adventurous, choose a paper that catches your interest from <a class="wiki_link_ext" href="http://web.mit.edu/cocosci/josh.html" rel="nofollow">Josh Tenenbaum’s home page</a>.<br>
                        <br>
                        <strong>February 8, 2011:</strong><br>
                        All group members read an article of their choosing from one of:<br>
                        <a class="wiki_link_ext" href="http://cognet.mit.edu.myaccess.library.utoronto.ca/" rel="nofollow">http://cognet.mit.edu.myaccess.library.utoronto.ca</a><br>
                        <a class="wiki_link_ext" href="http://www.megaupload.com/?d=6M4FLMQ1" rel="nofollow" target="_blank">http://www.megaupload.com/?d=6M4FLMQ1</a><br>
                        <br>
                        <strong>February 2, 2011:</strong><br>
                        <a class="wiki_link_ext" href="http://www.google.com/url?sa=t&amp;source=web&amp;cd=4&amp;ved=0CDcQFjAD&amp;url=http%3A%2F%2Fciteseer.ist.psu.edu%2Fviewdoc%2Fdownload%3Bjsessionid%3DFCF278FE3BA8EAAF718B8BEF8A4E5A1D%3Fdoi%3D10.1.1.132.8548%26rep%3Drep1%26type%3Dpdf&amp;rct=j&amp;q=irving%20biederman%2Brecognition%20by%20components&amp;ei=0mVATZ3uKITogQeiwqCTAw&amp;usg=AFQjCNEgT1MiHEuWGkhEuXeqCAIQ1PxERg" rel="nofollow">“Recognition-by-Components: A Theory of Human Image Understanding”</a> by Irving Biederman<br>
                        - a classical work — good preparation for Pablo’s talk<br>
                        <br>
                        <strong>January 25, 2011:</strong><br>
                        <a class="wiki_link_ext" href="http://marcade.robots.ox.ac.uk:8080/%7Evgg/publications/2008/Chum08a/chum08a.pdf" rel="nofollow">“Near Duplicate Image Detection min-Hash and tf-idf Weighting”</a> by O. Chum, J. Philbin, A. Zisserman<br>
                        - also available in the Readings section of UAIG’s drop-box<br>
                        <br>
                        <strong>January 18, 2011:</strong><br>
                        <a class="wiki_link_ext" href="http://www.icsd.aegean.gr/lecturers/stamatatos/" rel="nofollow">“A Survey of Modern Authorship Attribution Method”</a> by Efstathios Stamatatos<br>
                        <br>
                        <strong>January 11, 2011:</strong><br>
                        “<a class="wiki_link_ext" href="http://www.mitpressjournals.org/doi/pdf/10.1162/coli.2010.36.2.36201" rel="nofollow">What Computational Linguists Can Learn from Psychologists (and Vice Versa)</a>” by Emiel Krahmer<br>
                        “<a class="wiki_link_ext" href="http://www.mitpressjournals.org/doi/pdf/10.1162/coli.2009.35.4.35409" rel="nofollow">What Science Underlies Natural Language Engineering?</a>” by ShulyWintner<br>
                        <br>
                        <strong>December:</strong> Break: read what you like.<br>
                        <br>
                        <strong>November 29, 2010:</strong><br>
                        “Object recognition from local scale-invariant features” by David Lowe<br>
                        <a class="wiki_link_ext" href="http://www.cs.toronto.edu/%7Esven/Papers/cat2009.pdf" rel="nofollow">“The Evolution of Object Categorization and the Challenge of Image Abstraction”</a> by Sven Dickinson<br>
                        <br>
                        <strong>November 22, 2010:</strong><br>
                        “How Close Are We to Understanding V1?” by Olshausen and Field<br>
                        <br>
                        <strong>November 1, 2010:</strong><br>
                        Introduction to Machine Learning, Second Edition by Ethem Alpaydın<br>
                        - Book excerpt: pages 41-56<br>
                        <br>
                        <strong>Ongoing recommended reading:</strong><br>
                        “Artificial Intelligence: a Modern Approach” by Norvig+Russell<br>
                        <br>
                        <strong>Other suggested Readings</strong> (suggested by group members)<strong>:</strong><br>
                        “A cognitive neuroscience perspective on embodied language for 
                        human-robot cooperation.” by by Carol Madden, Michel Hoen, Peter Ford 
                        Dominey
                        <br>
                    </div>
                </div>  
        </div>
        <div id="menu_container">
            <div id="l_splash">UAIG</div>
            <div id="l_join">JOIN HERE!</div>        
            <div class="link" id="l_ai" style="margin-left: 360px; top: 270px;">AI</div>
            <div class="link" id="l_resources" style="margin-left: 340px; top: 367px;">RESOURCES</div>
            <div class="link" id="l_schedule" style="margin-left: 273px; top: 376px;">SCHEDULE</div>
            <div class="link" id="l_members" style="margin-left: 212px; top: 395px;">MEMBERS</div>
            <div class="link" id="l_links" style="margin-left: 134px; top: 384px;">LINKS</div>
            </div>
        </div>
        <div id="shadow"></div>
            <div id="banner">
                <a id="facebook" href="http://www.facebook.com/UofTUAIG" target="_TOP" title="UAIG"><img src="./facebook.png" /></a><a id="google" href="https://plus.google.com/110391532398292454919" target="_TOP" title="UAIG"><img src="./google.png" /></a>
            </div>
        <div id="banner_wrapper"></div>
        <div id="arrow_wrapper">
            <div class="floating" id="arrow"></div>
        </div>
        <div id="logo" style="font-size: 30%; text-align: right; line-height: 0%; opacity: 1; position: static; z-index: 120;"><img src="./uaiglogo.png" width="50" height="50" style="right: 16px; bottom: 35px; position: absolute;"></img><blah style="right: 20px; bottom: 25px; position: absolute;">Undergraduate AI Group @ U of T
            </div>
    </body>
</html>